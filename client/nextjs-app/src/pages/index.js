import { useEffect, useRef, useState, useCallback } from "react";
import Head from "next/head";

// ============================================================================
// CONFIGURATION
// ============================================================================
const CONFIG = {
  DETECTION_FPS: 1,
  HEARTBEAT_INTERVAL_MS: 10000,
  BATCH_INTERVAL_MS: 5000,
  THUMBNAIL_MIN_INTERVAL_MS: 30000,
  THUMBNAIL_MAX_SIZE_KB: 10,
  THUMBNAIL_WIDTH: 160,
  THUMBNAIL_HEIGHT: 90,
  // Anomaly thresholds
  FACE_MISSING_THRESHOLD_MS: 3000,
  LOOK_AWAY_THRESHOLD_MS: 5000,
  LOW_LIGHT_THRESHOLD: 50,
  LOW_LIGHT_DURATION_MS: 5000,
  CAMERA_BLOCKED_BRIGHTNESS: 10,
  CAMERA_BLOCKED_VARIANCE: 5,
  LOOK_AWAY_YAW_THRESHOLD: 30,
  LOOK_AWAY_PITCH_THRESHOLD: 25,
  MULTI_PERSON_CONSECUTIVE_FRAMES: 3,
};

const API_BASE = process.env.NEXT_PUBLIC_API_BASE || "http://localhost:8082";
const DEV_MODE = process.env.NEXT_PUBLIC_DEV_MODE !== "false";

// ============================================================================
// MAIN COMPONENT
// ============================================================================
export default function ProctoringPage() {
  const videoRef = useRef(null);
  const canvasRef = useRef(null);
  const faceDetectorRef = useRef(null);
  const faceLandmarkerRef = useRef(null);
  const detectionLoopRef = useRef(null);

  const [status, setStatus] = useState("INITIALIZING");
  const [sessionId, setSessionId] = useState(null);
  const [jwt, setJwt] = useState(null);
  const [events, setEvents] = useState([]);
  const [alerts, setAlerts] = useState([]);
  const [recentDetections, setRecentDetections] = useState([]);
  const [stats, setStats] = useState({ faceCount: 0, brightness: 0, lookAway: false });
  const [error, setError] = useState(null);
  const [connectionStatus, setConnectionStatus] = useState("CONNECTING");

  // Tracking state for anomaly detection
  const trackingRef = useRef({
    faceMissingSince: null,
    lookAwaySince: null,
    lowLightSince: null,
    multiPersonFrames: 0,
    lastThumbnailTime: 0,
    ackedEventIds: new Set(),
    pendingEvents: [],
  });

  // ============================================================================
  // DEV TOKEN AUTO-FETCH
  // ============================================================================
  const fetchDevToken = useCallback(async () => {
    if (!DEV_MODE) return null;
    try {
      const resp = await fetch(`${API_BASE}/proctoring/dev/token`, {
        method: "POST",
        headers: { "Content-Type": "application/json" },
        body: JSON.stringify({
          tenantId: "dev-tenant",
          examScheduleId: "dev-exam-" + Date.now(),
          userId: "dev-user-" + Math.floor(Math.random() * 10000),
          attemptNo: 1,
        }),
      });
      if (!resp.ok) throw new Error("Failed to get dev token");
      const data = await resp.json();
      return data.token;
    } catch (e) {
      console.error("Dev token fetch failed:", e);
      return null;
    }
  }, []);

  // ============================================================================
  // SESSION MANAGEMENT
  // ============================================================================
  const startSession = useCallback(async (token) => {
    try {
      const resp = await fetch(`${API_BASE}/proctoring/sessions/start`, {
        method: "POST",
        headers: {
          "Content-Type": "application/json",
          Authorization: `Bearer ${token}`,
        },
        body: JSON.stringify({
          examConfig: {
            maxLookAwaySeconds: CONFIG.LOOK_AWAY_THRESHOLD_MS / 1000,
            maxLookAwayWindowSeconds: 30,
          },
        }),
      });
      if (!resp.ok) throw new Error("Session start failed");
      const data = await resp.json();
      return data.sessionId;
    } catch (e) {
      console.error("Start session error:", e);
      throw e;
    }
  }, []);

  const endSession = useCallback(async () => {
    if (!sessionId || !jwt) return;
    try {
      await fetch(`${API_BASE}/proctoring/sessions/end`, {
        method: "POST",
        headers: { Authorization: `Bearer ${jwt}` },
      });
      setStatus("COMPLETED");
      setConnectionStatus("DISCONNECTED");
      if (detectionLoopRef.current) clearInterval(detectionLoopRef.current);
      if (videoRef.current && videoRef.current.srcObject) {
        videoRef.current.srcObject.getTracks().forEach(t => t.stop());
      }
    } catch (e) {
      console.error(e);
      setError("Failed to end session");
    }
  }, [sessionId, jwt]);

  // ============================================================================
  // EVENT BATCHING WITH RETRY
  // ============================================================================
  const sendBatch = useCallback(async () => {
    const tracking = trackingRef.current;
    if (!jwt || !sessionId || tracking.pendingEvents.length === 0) return;

    const batch = tracking.pendingEvents.filter(
      (e) => !tracking.ackedEventIds.has(e.eventId)
    );
    if (batch.length === 0) return;

    try {
      const resp = await fetch(`${API_BASE}/proctoring/events/batch`, {
        method: "POST",
        headers: {
          "Content-Type": "application/json",
          Authorization: `Bearer ${jwt}`,
        },
        body: JSON.stringify({
          sessionId,
          events: batch.map((e) => ({
            eventId: e.eventId,
            type: e.type,
            timestamp: e.timestamp,
            confidence: e.confidence,
            severity: e.severity,
            details: e.details,
          })),
          thumbnails: batch
            .filter((e) => e.thumbnail)
            .map((e) => ({
              eventId: e.eventId,
              contentType: "image/jpeg",
              dataBase64: e.thumbnail,
              sizeBytes: Math.round((e.thumbnail.length * 3) / 4),
            })),
        }),
      });

      if (resp.ok) {
        const result = await resp.json();
        result.acceptedEventIds?.forEach((id) => tracking.ackedEventIds.add(id));
        tracking.pendingEvents = tracking.pendingEvents.filter(
          (e) => !tracking.ackedEventIds.has(e.eventId)
        );
        setConnectionStatus("CONNECTED");
      } else {
        setConnectionStatus("RECONNECTING");
      }
    } catch (e) {
      console.error("Batch send failed:", e);
      setConnectionStatus("DISCONNECTED");
    }
  }, [jwt, sessionId]);

  // ============================================================================
  // POLL ALERTS
  // ============================================================================
  const pollAlerts = useCallback(async () => {
    if (!jwt || !sessionId) return;
    try {
      const resp = await fetch(`${API_BASE}/proctoring/sessions/${sessionId}/alerts`, {
        headers: { Authorization: `Bearer ${jwt}` },
      });
      if (resp.ok) {
        const data = await resp.json();
        setAlerts(data.alerts || []);
      }
    } catch (e) {
      console.error("Poll alerts failed:", e);
    }
  }, [jwt, sessionId]);

  // ============================================================================
  // ADD ANOMALY EVENT
  // ============================================================================
  const addEvent = useCallback((type, severity, confidence, details = {}, captureThumbnail = false) => {
    const tracking = trackingRef.current;
    const now = Date.now();
    const eventId = `evt-${now}-${Math.random().toString(36).substring(2, 8)}`;

    let thumbnail = null;
    if (captureThumbnail && now - tracking.lastThumbnailTime > CONFIG.THUMBNAIL_MIN_INTERVAL_MS) {
      thumbnail = captureThumbnailImage();
      if (thumbnail) tracking.lastThumbnailTime = now;
    }

    const event = {
      eventId,
      type,
      timestamp: new Date().toISOString(),
      confidence,
      severity,
      details,
      thumbnail,
    };

    tracking.pendingEvents.push(event);
    setEvents((prev) => [...prev.slice(-49), event]);
    setRecentDetections((prev) => [
      { type, severity, time: new Date().toLocaleTimeString() },
      ...prev.slice(0, 4),
    ]);
  }, []);

  // ============================================================================
  // THUMBNAIL CAPTURE
  // ============================================================================
  const captureThumbnailImage = useCallback(() => {
    const video = videoRef.current;
    const canvas = canvasRef.current;
    if (!video || !canvas) return null;

    const ctx = canvas.getContext("2d");
    canvas.width = CONFIG.THUMBNAIL_WIDTH;
    canvas.height = CONFIG.THUMBNAIL_HEIGHT;
    ctx.drawImage(video, 0, 0, CONFIG.THUMBNAIL_WIDTH, CONFIG.THUMBNAIL_HEIGHT);

    let quality = 0.7;
    let dataUrl = canvas.toDataURL("image/jpeg", quality);
    while (dataUrl.length > CONFIG.THUMBNAIL_MAX_SIZE_KB * 1024 * 1.37 && quality > 0.1) {
      quality -= 0.1;
      dataUrl = canvas.toDataURL("image/jpeg", quality);
    }
    return dataUrl.split(",")[1];
  }, []);

  // ============================================================================
  // IMAGE ANALYSIS UTILITIES
  // ============================================================================
  const analyzeFrame = useCallback((video) => {
    const canvas = document.createElement("canvas");
    canvas.width = 64;
    canvas.height = 36;
    const ctx = canvas.getContext("2d");
    ctx.drawImage(video, 0, 0, 64, 36);
    const imageData = ctx.getImageData(0, 0, 64, 36);
    const data = imageData.data;

    let totalBrightness = 0;
    let brightnessValues = [];
    for (let i = 0; i < data.length; i += 4) {
      const brightness = (data[i] + data[i + 1] + data[i + 2]) / 3;
      totalBrightness += brightness;
      brightnessValues.push(brightness);
    }
    const avgBrightness = totalBrightness / (data.length / 4);

    let variance = 0;
    for (const b of brightnessValues) {
      variance += (b - avgBrightness) ** 2;
    }
    variance /= brightnessValues.length;

    return { brightness: avgBrightness, variance };
  }, []);

  const estimateHeadPose = useCallback((landmarks) => {
    if (!landmarks || landmarks.length < 468) return { yaw: 0, pitch: 0 };

    const noseTip = landmarks[1];
    const leftEye = landmarks[33];
    const rightEye = landmarks[263];
    const chin = landmarks[152];
    const forehead = landmarks[10];

    const eyeCenter = {
      x: (leftEye.x + rightEye.x) / 2,
      y: (leftEye.y + rightEye.y) / 2,
    };

    const yaw = (noseTip.x - eyeCenter.x) * 180;
    const pitch = (noseTip.y - (forehead.y + chin.y) / 2) * 180;

    return { yaw, pitch };
  }, []);

  // ============================================================================
  // MEDIAPIPE INITIALIZATION
  // ============================================================================
  const initMediaPipe = useCallback(async () => {
    try {
      const vision = await import("@mediapipe/tasks-vision");
      const { FaceDetector, FaceLandmarker, FilesetResolver } = vision;

      const filesetResolver = await FilesetResolver.forVisionTasks(
        "https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.14/wasm"
      );

      faceDetectorRef.current = await FaceDetector.createFromOptions(filesetResolver, {
        baseOptions: {
          modelAssetPath:
            "https://storage.googleapis.com/mediapipe-models/face_detector/blaze_face_short_range/float16/1/blaze_face_short_range.tflite",
          delegate: "GPU",
        },
        runningMode: "VIDEO",
        minDetectionConfidence: 0.5,
      });

      faceLandmarkerRef.current = await FaceLandmarker.createFromOptions(filesetResolver, {
        baseOptions: {
          modelAssetPath:
            "https://storage.googleapis.com/mediapipe-models/face_landmarker/face_landmarker/float16/1/face_landmarker.task",
          delegate: "GPU",
        },
        runningMode: "VIDEO",
        numFaces: 1,
        outputFaceBlendshapes: false,
        outputFacialTransformationMatrixes: false,
      });

      return true;
    } catch (e) {
      console.error("MediaPipe init failed:", e);
      return false;
    }
  }, []);

  // ============================================================================
  // DETECTION LOOP
  // ============================================================================
  const runDetection = useCallback(() => {
    const video = videoRef.current;
    const faceDetector = faceDetectorRef.current;
    const faceLandmarker = faceLandmarkerRef.current;
    const tracking = trackingRef.current;

    if (!video || !faceDetector || video.readyState < 2) return;

    const now = Date.now();
    const timestamp = performance.now();

    try {
      // Face detection
      const detections = faceDetector.detectForVideo(video, timestamp);
      const faceCount = detections.detections?.length || 0;

      // Frame analysis
      const { brightness, variance } = analyzeFrame(video);

      // Landmark detection for head pose (only if one face)
      let lookAway = false;
      if (faceCount === 1 && faceLandmarker) {
        try {
          const landmarkResult = faceLandmarker.detectForVideo(video, timestamp);
          if (landmarkResult.faceLandmarks?.[0]) {
            const { yaw, pitch } = estimateHeadPose(landmarkResult.faceLandmarks[0]);
            lookAway =
              Math.abs(yaw) > CONFIG.LOOK_AWAY_YAW_THRESHOLD ||
              Math.abs(pitch) > CONFIG.LOOK_AWAY_PITCH_THRESHOLD;
          }
        } catch (e) {
          // Landmarker may fail occasionally, ignore
        }
      }

      setStats({ faceCount, brightness: Math.round(brightness), lookAway });

      // ========== ANOMALY DETECTION LOGIC ==========

      // MULTI_PERSON
      if (faceCount > 1) {
        tracking.multiPersonFrames++;
        if (tracking.multiPersonFrames >= CONFIG.MULTI_PERSON_CONSECUTIVE_FRAMES) {
          addEvent("MULTI_PERSON", "CRITICAL", 0.95, { faceCount }, true);
          tracking.multiPersonFrames = 0;
        }
      } else {
        tracking.multiPersonFrames = 0;
      }

      // FACE_MISSING
      if (faceCount === 0) {
        if (!tracking.faceMissingSince) tracking.faceMissingSince = now;
        if (now - tracking.faceMissingSince > CONFIG.FACE_MISSING_THRESHOLD_MS) {
          addEvent("FACE_MISSING", "HIGH", 0.9, {
            durationMs: now - tracking.faceMissingSince,
          }, true);
          tracking.faceMissingSince = now; // Reset to avoid spam
        }
      } else {
        tracking.faceMissingSince = null;
      }

      // LOOK_AWAY
      if (lookAway && faceCount === 1) {
        if (!tracking.lookAwaySince) tracking.lookAwaySince = now;
        if (now - tracking.lookAwaySince > CONFIG.LOOK_AWAY_THRESHOLD_MS) {
          addEvent("LOOK_AWAY", "MEDIUM", 0.85, {
            durationMs: now - tracking.lookAwaySince,
          });
          tracking.lookAwaySince = now;
        }
      } else {
        tracking.lookAwaySince = null;
      }

      // LIGHTING_LOW
      if (brightness < CONFIG.LOW_LIGHT_THRESHOLD) {
        if (!tracking.lowLightSince) tracking.lowLightSince = now;
        if (now - tracking.lowLightSince > CONFIG.LOW_LIGHT_DURATION_MS) {
          addEvent("LIGHTING_LOW", "LOW", 0.7, { brightness });
          tracking.lowLightSince = now;
        }
      } else {
        tracking.lowLightSince = null;
      }

      // CAMERA_BLOCKED
      if (
        brightness < CONFIG.CAMERA_BLOCKED_BRIGHTNESS &&
        variance < CONFIG.CAMERA_BLOCKED_VARIANCE
      ) {
        addEvent("CAMERA_BLOCKED", "HIGH", 0.95, { brightness, variance }, true);
      }
    } catch (e) {
      console.error("Detection error:", e);
    }
  }, [addEvent, analyzeFrame, estimateHeadPose]);

  // ============================================================================
  // INITIALIZATION EFFECT
  // ============================================================================
  useEffect(() => {
    let mounted = true;

    const initialize = async () => {
      setStatus("INITIALIZING");
      setError(null);

      // 1. Get camera permission
      try {
        const stream = await navigator.mediaDevices.getUserMedia({
          video: { width: 640, height: 360, facingMode: "user" },
          audio: false,
        });
        if (!mounted) return;
        if (videoRef.current) {
          videoRef.current.srcObject = stream;
          await new Promise((resolve) => {
            videoRef.current.onloadedmetadata = resolve;
          });
        }
      } catch (e) {
        setError("Camera permission denied. Please allow camera access.");
        setStatus("ERROR");
        return;
      }

      // 2. Initialize MediaPipe
      setStatus("LOADING_ML");
      const mlReady = await initMediaPipe();
      if (!mounted) return;
      if (!mlReady) {
        setError("Failed to load ML models. Please refresh.");
        setStatus("ERROR");
        return;
      }

      // 3. Get JWT (dev mode auto-fetch)
      setStatus("AUTHENTICATING");
      let token = jwt;
      if (!token && DEV_MODE) {
        token = await fetchDevToken();
        if (!mounted) return;
        if (token) setJwt(token);
      }

      if (!token) {
        setError("Authentication failed. No valid token.");
        setStatus("ERROR");
        return;
      }

      // 4. Start session
      setStatus("STARTING_SESSION");
      try {
        const sid = await startSession(token);
        if (!mounted) return;
        setSessionId(sid);
        setStatus("ACTIVE");
        setConnectionStatus("CONNECTED");
      } catch (e) {
        setError("Failed to start proctoring session.");
        setStatus("ERROR");
        return;
      }
    };

    initialize();

    return () => {
      mounted = false;
      if (detectionLoopRef.current) clearInterval(detectionLoopRef.current);
    };
  }, [initMediaPipe, fetchDevToken, startSession, jwt]);

  // ============================================================================
  // DETECTION LOOP EFFECT
  // ============================================================================
  useEffect(() => {
    if (status !== "ACTIVE") return;

    detectionLoopRef.current = setInterval(runDetection, 1000 / CONFIG.DETECTION_FPS);

    return () => {
      if (detectionLoopRef.current) clearInterval(detectionLoopRef.current);
    };
  }, [status, runDetection]);

  // ============================================================================
  // BATCH & HEARTBEAT EFFECT
  // ============================================================================
  useEffect(() => {
    if (status !== "ACTIVE") return;

    const batchInterval = setInterval(sendBatch, CONFIG.BATCH_INTERVAL_MS);
    const alertInterval = setInterval(pollAlerts, CONFIG.HEARTBEAT_INTERVAL_MS);

    return () => {
      clearInterval(batchInterval);
      clearInterval(alertInterval);
    };
  }, [status, sendBatch, pollAlerts]);

  // ============================================================================
  // RENDER
  // ============================================================================
  const statusColors = {
    INITIALIZING: "bg-yellow-500",
    LOADING_ML: "bg-yellow-500",
    AUTHENTICATING: "bg-yellow-500",
    STARTING_SESSION: "bg-yellow-500",
    ACTIVE: "bg-emerald-500",
    ERROR: "bg-red-500",
  };

  const connectionColors = {
    CONNECTING: "text-yellow-400",
    CONNECTED: "text-emerald-400",
    RECONNECTING: "text-orange-400",
    DISCONNECTED: "text-red-400",
  };

  return (
    <>
      <Head>
        <title>AI Exam Proctoring</title>
        <meta name="description" content="Real-time AI-powered exam proctoring" />
      </Head>

      <div className="min-h-screen bg-gradient-to-br from-slate-900 via-slate-800 to-slate-900 text-white p-4">
        <div className="max-w-6xl mx-auto space-y-4">
          {/* Header */}
          <header className="flex items-center justify-between bg-slate-800/50 backdrop-blur rounded-xl p-4 border border-slate-700">
            <div className="flex items-center gap-3">
              <div className={`w-3 h-3 rounded-full ${statusColors[status]} animate-pulse`} />
              <h1 className="text-lg font-bold text-sky-400">AI Exam Proctoring</h1>
            </div>
            <div className="flex items-center gap-4 text-sm">
              <span className={connectionColors[connectionStatus]}>
                ‚óè {connectionStatus}
              </span>
              <span className="text-slate-400">
                Session: {sessionId ? sessionId.substring(0, 8) + "..." : "‚Äî"}
              </span>
              {status === "ACTIVE" && (
                <button
                  onClick={endSession}
                  className="bg-red-500/80 hover:bg-red-500 text-white px-3 py-1 rounded text-xs font-semibold"
                >
                  End Session
                </button>
              )}
            </div>
          </header>

          {/* Error Display */}
          {error && (
            <div className="bg-red-500/20 border border-red-500 rounded-xl p-4 text-red-200">
              <p className="font-semibold">Error</p>
              <p className="text-sm">{error}</p>
            </div>
          )}

          {/* Main Content */}
          <div className="grid grid-cols-1 lg:grid-cols-3 gap-4">
            {/* Video Feed */}
            <div className="lg:col-span-2 space-y-4">
              <div className="relative bg-black rounded-xl overflow-hidden border border-slate-700">
                <video
                  ref={videoRef}
                  autoPlay
                  playsInline
                  muted
                  className="w-full aspect-video object-cover"
                />
                <canvas ref={canvasRef} className="hidden" />

                {/* Overlay Stats */}
                <div className="absolute top-2 left-2 bg-black/60 backdrop-blur rounded-lg px-3 py-2 text-xs space-y-1">
                  <div className="flex items-center gap-2">
                    <span className={stats.faceCount === 1 ? "text-emerald-400" : "text-red-400"}>
                      üë§ Faces: {stats.faceCount}
                    </span>
                  </div>
                  <div className={stats.brightness > 50 ? "text-emerald-400" : "text-yellow-400"}>
                    üí° Light: {stats.brightness}%
                  </div>
                  <div className={stats.lookAway ? "text-red-400" : "text-emerald-400"}>
                    üëÅ Focus: {stats.lookAway ? "Looking Away" : "OK"}
                  </div>
                </div>

                {/* Status Badge */}
                <div className="absolute bottom-2 right-2">
                  <span
                    className={`px-3 py-1 rounded-full text-xs font-semibold ${status === "ACTIVE"
                      ? "bg-emerald-500/80 text-white"
                      : status === "ERROR"
                        ? "bg-red-500/80 text-white"
                        : "bg-yellow-500/80 text-black"
                      }`}
                  >
                    {status}
                  </span>
                </div>
              </div>
            </div>

            {/* Side Panel */}
            <div className="space-y-4">
              {/* Recent Detections */}
              <div className="bg-slate-800/50 backdrop-blur rounded-xl p-4 border border-slate-700">
                <h2 className="text-sm font-semibold text-slate-300 mb-3">
                  Recent Detections
                </h2>
                <div className="space-y-2 max-h-40 overflow-y-auto">
                  {recentDetections.length === 0 ? (
                    <p className="text-xs text-slate-500">No anomalies detected</p>
                  ) : (
                    recentDetections.map((d, i) => (
                      <div
                        key={i}
                        className={`text-xs p-2 rounded border ${d.severity === "CRITICAL"
                          ? "bg-red-500/20 border-red-500 text-red-200"
                          : d.severity === "HIGH"
                            ? "bg-orange-500/20 border-orange-500 text-orange-200"
                            : d.severity === "MEDIUM"
                              ? "bg-yellow-500/20 border-yellow-500 text-yellow-200"
                              : "bg-slate-700/50 border-slate-600 text-slate-300"
                          }`}
                      >
                        <span className="font-semibold">{d.type}</span>
                        <span className="float-right text-slate-400">{d.time}</span>
                      </div>
                    ))
                  )}
                </div>
              </div>

              {/* Alerts from Backend */}
              <div className="bg-slate-800/50 backdrop-blur rounded-xl p-4 border border-slate-700">
                <h2 className="text-sm font-semibold text-slate-300 mb-3">
                  Server Alerts
                </h2>
                <div className="space-y-2 max-h-40 overflow-y-auto">
                  {alerts.length === 0 ? (
                    <p className="text-xs text-slate-500">No alerts from server</p>
                  ) : (
                    alerts.slice(0, 5).map((a, i) => (
                      <div
                        key={i}
                        className="text-xs p-2 rounded bg-red-500/20 border border-red-500 text-red-200"
                      >
                        <span className="font-semibold">{a.type}</span>
                        <span className="ml-2 text-red-300">[{a.severity}]</span>
                      </div>
                    ))
                  )}
                </div>
              </div>

              {/* Queue Status */}
              <div className="bg-slate-800/50 backdrop-blur rounded-xl p-4 border border-slate-700">
                <h2 className="text-sm font-semibold text-slate-300 mb-2">
                  Event Queue
                </h2>
                <p className="text-2xl font-bold text-sky-400">
                  {trackingRef.current.pendingEvents.length}
                </p>
                <p className="text-xs text-slate-500">pending events</p>
              </div>
            </div>
          </div>

          {/* Footer */}
          <footer className="text-center text-xs text-slate-500 py-4">
            AI Exam Proctoring ‚Ä¢ Real-time on-device detection powered by MediaPipe
          </footer>
        </div>
      </div>
    </>
  );
}
